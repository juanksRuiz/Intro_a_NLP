{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I: Implementacion de un sistema de Reconocimiento Automático de Habla.\n",
    "\n",
    "El objetivo de este proyecto es utilizar las herramientas vistas en clase para la implementación de un sistema de reconocimiento automático de habla (ASR-Automatic Speech Recognition). Para lograr este objetivo se realizarán dos implementaciones. La primera de ellas utilizará HMM, y est definida en el **Taller II: Implementing a simple ASR system using HMM**. La segunda Implementación se realizará utilizando redes Neuronales Reurrentes (RNN).\n",
    "\n",
    "Par al aimplementación del sistema utilizando RNNs, se utilizara la libreria [TensorFlow](https://pypi.org/project/tensorflow/) de Python, especificamente las funciones para la creación de redes neuronales en [keras](https://www.tensorflow.org/guide/keras/sequential_model) y en particular las relacionadas con las redes neuronales recurrentes [(RNN)](https://www.tensorflow.org/guide/keras/rnn). Pueden utilizar las RNN simples, LTSM o las GRU. Sin emabrgo, las que se estudiaron en clase hasta el momento son las RNN simples. Por otro lado no es necesario que usen las RNNs bidirecionales, o las funciones optimizadas par aGPUs.\n",
    "\n",
    "Para este taller deben seguir los siguientes pasos:\n",
    "\n",
    "1. Cree una base de datos de entrenamiento, utilizando la segmentación de las palabras en fonemas y los espectrogramas de la señal de voz calculados en el Taller II.\n",
    "2. Divida los datos entre datos de entrenamiento y validación. Esto lo puede realizar por medio del uso de  la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de SciKit-Learn.\n",
    "3. Construya un aarquitectura para el ASR usando redes neuronales.\n",
    "4. Evalue el comportamiento del modelo.\n",
    "5. Ajuste el modelo si lo considera adecuado.\n",
    "6. Pruebe con los datos de entrenamiento si el modelo produce la secuencia de fonemas indicada.\n",
    "7. Con el conjunto de palabras de prueba, generado en el taller II, trate de predecir la palbara escrita utilizando el modelo implementado.\n",
    "8. Discuta sobre el comportamiento del sistema ASR utilziando HMM y RNN. La discusión debe contener al menos la respuest aa las siguientes pregutnas:\n",
    "    * ¿Cúal modelo e smás facil de entender?\n",
    "    * ¿Qué modelo funciona mejor? ¿Cúal es la razón para esto?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en HMM?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en RNN?\n",
    "    * ¿Cómo se podria mejorar el sistema desarrollado? ¿Qué hace falta en este sistema ASR?\n",
    "    * ¿Obtuvó los resultados esperados?\n",
    "    \n",
    "Al enviar el proyecto debe incluir los siguientes items:\n",
    "1. Notebook de Jupyter explicando el desarrollo del proyecto, y con la respuesta a las preguntas realiadas.\n",
    "2. Archivos de soporte utilizadso, funciones, etc..\n",
    "3. Grabaciones de las señales de voz utilizadas para entrenar el sistema.\n",
    "4. Grabaciones de las señales de voz utilizadas para probar el sistema.\n",
    "\n",
    "**Nota I:** Una guía rápida par ala implementación del modelo de red neuronal utilizando TensorFlow y Python lo pueden encontrar en este [link](https://www.youtube.com/watch?v=BSpXCRTOLJA).\n",
    "\n",
    "**Nota II:** Recuerde que este proyecto se realiza en grupos de máximo dos personas. También tenga en cuenta que debido a que el taller II hace parte de la evaluación, deben hacerse con el mismo compañero con el que trabajarón ese taller.\n",
    "\n",
    "**Nota III:** El deadline par ala entrega del proyecto es el **Domingo 28 de Febrero del 2021**.\n",
    "\n",
    "**Mucha Suerte!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import scipy as sc\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 8000 # Numero de muestras por segundo\n",
    "nBits = 16 # Numero de bits por muestra del audio\n",
    "ID = -1\n",
    "seconds = 5 # Duracion de la grabacion\n",
    "Nfft = 512\n",
    "fm = np.arange(0, Nfft / 4) * fs / Nfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahijado.wav',\n",
       " 'balocesto.wav',\n",
       " 'espantapajaro.wav',\n",
       " 'jamon.wav',\n",
       " 'kiosko.wav',\n",
       " 'llorar.wav',\n",
       " 'muchacho.wav',\n",
       " 'murcielago.wav',\n",
       " 'sound1.wav',\n",
       " 'sound10.wav',\n",
       " 'sound2.wav',\n",
       " 'sound3.wav',\n",
       " 'sound4.wav',\n",
       " 'sound5.wav',\n",
       " 'sound6.wav',\n",
       " 'sound7.wav',\n",
       " 'sound8.wav',\n",
       " 'sound9.wav',\n",
       " 'terremoto.wav',\n",
       " 'zapato.wav']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = os.listdir('./utils/sounds/')\n",
    "nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras de prueba:\n",
    "### Para test\n",
    "1. Tapabocas\n",
    "2. Teclado\n",
    "3. Cucaracha\n",
    "4. Estornudar\n",
    "5. Coronavirus\n",
    "\n",
    "6. Vacuna\n",
    "7. Escoba\n",
    "8. Recogedor\n",
    "9. Trapero\n",
    "10. Sosobra\n",
    "\n",
    "### Palabras con raiz similar\n",
    "1. Fechoría\n",
    "2. Fetiche\n",
    "3. Satisfecho\n",
    "\n",
    "4. Zapatería\n",
    "5. Zapatero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahijado.wav': 7,\n",
       " 'balocesto.wav': 10,\n",
       " 'espantapajaro.wav': 13,\n",
       " 'jamon.wav': 5,\n",
       " 'kiosko.wav': 6,\n",
       " 'llorar.wav': 5,\n",
       " 'muchacho.wav': 6,\n",
       " 'murcielago.wav': 10,\n",
       " 'sound1.wav': 4,\n",
       " 'sound10.wav': 8,\n",
       " 'sound2.wav': 5,\n",
       " 'sound3.wav': 5,\n",
       " 'sound4.wav': 5,\n",
       " 'sound5.wav': 8,\n",
       " 'sound6.wav': 6,\n",
       " 'sound7.wav': 7,\n",
       " 'sound8.wav': 6,\n",
       " 'sound9.wav': 5,\n",
       " 'terremoto.wav': 8,\n",
       " 'zapato.wav': 6}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantidad_fonemas = [7,10,13,5,6,5,6,10,4,8,5,5,5,8,6,7,6,5,8,6]\n",
    "dicc = {}\n",
    "for idx,i in enumerate(nombres):\n",
    "    dicc[i] = cantidad_fonemas[idx]\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAudios(nombres):\n",
    "    audios = []\n",
    "    for i in nombres:\n",
    "        y_aux, fs_aux = sf.read('./utils/sounds/' + i)\n",
    "        if len(y_aux.shape) > 1:\n",
    "            y_aux = y_aux[:,0]\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        else:\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        audios.append(y)\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMelSpectogram(audios,fs,Nfft):\n",
    "    spectograms = []\n",
    "    for i in audios:\n",
    "        Sm = librosa.feature.melspectrogram(y=i, sr=fs, n_fft=Nfft, n_mels = 39)\n",
    "        spectograms.append(Sm)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = getAudios(nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectograms = getMelSpectogram(audios,fs,Nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_codificadas = [[1,9,10,11,1,5,18], [2,1,13,18,16,3,6,22,23,18],[6,22,19,1,16,23,1,19,1,11,1,20,18],\n",
    "                        [11,1,15,18,16],[12,10,18,22,12,18], [14,18,20,1,20],[15,24,4,1,4,18],[15,24,20,3,10,6,13,1,8,18],\n",
    "                        [7,6,4,1], [2,10,14,6,23,6,20,1],[13,10,2,20,18],[13,1,19,10,3],[12,18,21,6,20],[23,6,13,6,7,18,16,18],\n",
    "                        [19,24,6,20,23,1],[19,1,16,23,1,14,1],[11,10,15,6,16,1],[21,6,8,13,1],[23,6,21,6,15,18,23,18],[3,1,19,1,23,18]]\n",
    "for p in palabras_codificadas:\n",
    "    p.insert(0,0)\n",
    "    p.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_countFon = {}\n",
    "for i in range(0,27):\n",
    "    ocurrencia = 0\n",
    "    for j in palabras_codificadas:\n",
    "        ocurrencia += j.count(i)\n",
    "    dicc_countFon[i] = ocurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneCode(palabras_codificadas):\n",
    "    palabras_onecode = []\n",
    "    for palabra in palabras_codificadas:\n",
    "        matriz = np.zeros((24,len(palabra)))\n",
    "        for i in range(len(palabra)):\n",
    "            if palabra[i] > 17 and palabra[i] <= 24:\n",
    "                matriz[palabra[i] - 1,i] = 1\n",
    "            else:\n",
    "                matriz[palabra[i],i] = 1\n",
    "        palabras_onecode.append(matriz)\n",
    "    return palabras_onecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_1_0 = getOneCode(palabras_codificadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta\n",
    "\n",
    "Cual es la interpretacion de realizar el split de esta forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada matriz de entrenamiento tiene 39 filas y n columnas\n",
    "X_train, X_test, y_train, y_test = train_test_split(Spectograms, matrices_1_0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 8),\n",
       " (24, 9),\n",
       " (24, 10),\n",
       " (24, 7),\n",
       " (24, 9),\n",
       " (24, 10),\n",
       " (24, 12),\n",
       " (24, 8),\n",
       " (24, 8),\n",
       " (24, 10),\n",
       " (24, 7),\n",
       " (24, 15),\n",
       " (24, 8),\n",
       " (24, 6)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.shape for m in y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "## Modificación de las dimensiones de X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando matriz de espectrograma a tensor\n",
    "# Se crea un tensor de (p,q,r) con p: numero de espectrogramas, q: numero de filas, r: numero de columnas\n",
    "# r se fija en el valor maximo de numero de columnas entre todos los espectrogramas para que todos los \n",
    "# espectrogramas tengan la misma dimension en el tensor\n",
    "\n",
    "\n",
    "# cada espectrograma de X tiene dimension (39,max_cols) siendo max_cols\n",
    "# el numero maximo de columnas entre todos los espectrogramas\n",
    "\n",
    "# Para datos de entrenamiento \n",
    "max_dim_tr = max([X_train[i].shape[1] for i in range(len(X_train))])\n",
    "X_tr_new = np.zeros((len(X_train),max_dim_tr,39))\n",
    "for i in range(len(X_tr_new)):\n",
    "    X_tr_new[i,0:X_train[i].shape[1],:] = X_train[i].T\n",
    "    \n",
    "# Para datos de prueba\n",
    "max_dim_test = max([X_test[i].shape[1] for i in range(len(X_test))])\n",
    "X_test_new = np.zeros((len(X_test),max_dim_test,39))\n",
    "for i in range(len(X_test_new)):\n",
    "    X_test_new[i,0:X_test[i].shape[1],:] = X_test[i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 242, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24),\n",
       " (15, 24)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_tr_new.shape)\n",
    "#[m.shape for m in y_tr_new] # (15, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificacion de dimensiones de y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se agrega columnas de silencio a las matrices de y tal que cada matriz de y_train y y_test\n",
    "# (por separado) tiene dimension (24,max_n_train) o (24,max_n_test) \n",
    "\n",
    "# Para outputs de entrenamiento \n",
    "max_dim_tr = max([y_train[i].shape[1] for i in range(len(y_train))])\n",
    "max_dim_test = max([y_test[i].shape[1] for i in range(len(y_test))])\n",
    "MAX = max([max_dim_tr,max_dim_test])\n",
    "\n",
    "y_train_new = []\n",
    "new_col = np.array([1]+23*[0]).reshape([24,1])\n",
    "for i in range(len(y_train)):\n",
    "    mat_copy = deepcopy(y_train[i])\n",
    "    add_left_flag = True\n",
    "    while mat_copy.shape[1] < MAX:\n",
    "        if add_left_flag:\n",
    "            mat_copy = np.concatenate([new_col,mat_copy],axis=1)\n",
    "        else:\n",
    "            mat_copy = np.concatenate([mat_copy,new_col],axis=1)\n",
    "    y_train_new.append(mat_copy)\n",
    "\n",
    "# Para datos de prueba\n",
    "y_test_new = []\n",
    "new_col = np.array([1]+23*[0]).reshape([24,1])\n",
    "for i in range(len(y_test)):\n",
    "    mat_copy = deepcopy(y_test[i])\n",
    "    add_left_flag = True\n",
    "    while mat_copy.shape[1] < MAX:\n",
    "        if add_left_flag:\n",
    "            mat_copy = np.concatenate([new_col,mat_copy],axis=1)\n",
    "        else:\n",
    "            mat_copy = np.concatenate([mat_copy,new_col],axis=1)\n",
    "    y_test_new.append(mat_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando outputs de entrenamiento y de salida en tensores\n",
    "\n",
    "# Para y_train\n",
    "y_tr_new = np.zeros((len(y_train_new), y_train_new[0].shape[1], y_train_new[0].shape[0]))\n",
    "for i in range(len(y_train_new)):\n",
    "    y_tr_new[i,:,:] = y_train_new[i].T\n",
    "    \n",
    "# Para y_test\n",
    "y_tes_new = np.zeros((len(y_test_new), y_test_new[0].shape[1], y_test_new[0].shape[0]))\n",
    "for i in range(len(y_test_new)):\n",
    "    y_tes_new[i,:,:] = y_test_new[i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 15, 24)\n",
      "(6, 15, 24)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr_new.shape)\n",
    "print(y_tes_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 1 de RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Numero arbitrario?\n",
    "model.add(LSTM(128, input_shape=(X_tr_new.shape[1:]), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.001))\n",
    "\n",
    "#model.add(LSTM(128, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(24, input_shape=(X_tr_new.shape[1:]), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Capa de salida: numero de clases de salida: numero de fonemas utilizados\n",
    "#n_out = 24 # fonemas que aparecen en palabras incluyebndo el silencio\n",
    "#model.add(Dense(n_out, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 2 de RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(12, input_shape=(X_tr_new.shape[1:]), return_sequences=True))\n",
    "model.add(tf.keras.layers.TimeDistributed(Dense(24)))\n",
    "\n",
    "#model.add(tf.keras.layers.Lambda(lambda x: x[:, -24:, :])) #Select last N from output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intento 3 de RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  \n",
    "model.add(LSTM(24,input_dim=39, return_sequences=False))\n",
    "model.add(Dense(24,tf.keras.layers.Activation('relu')))\n",
    "#\n",
    "model.add(tf.keras.layers.RepeatVector(y_train_new[0].shape[1])) # columnas en y (param.2)\n",
    "model.add(LSTM(24, return_sequences=True))  \n",
    "# Capa de salida\n",
    "model.add(tf.keras.layers.TimeDistributed(Dense(24)))\n",
    "model.add(tf.keras.layers.Activation('linear'))\n",
    "#opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-8) # rmsprop\n",
    "model.compile(loss='mean_squared_error', optimizer=\"rmsprop\", metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-8)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr_new.shape)\n",
    "print(y_tr_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_new.shape)\n",
    "print(y_tes_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.0422 - accuracy: 0.1190 - val_loss: 0.0402 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0403 - accuracy: 0.4571 - val_loss: 0.0389 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0392 - accuracy: 0.5238 - val_loss: 0.0379 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.0383 - accuracy: 0.5286 - val_loss: 0.0370 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0376 - accuracy: 0.5286 - val_loss: 0.0362 - val_accuracy: 0.6000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0369 - accuracy: 0.5286 - val_loss: 0.0355 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0362 - accuracy: 0.5286 - val_loss: 0.0348 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 382ms/step - loss: 0.0356 - accuracy: 0.5286 - val_loss: 0.0342 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.0351 - accuracy: 0.5286 - val_loss: 0.0337 - val_accuracy: 0.6000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.0346 - accuracy: 0.5286 - val_loss: 0.0331 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0341 - accuracy: 0.5286 - val_loss: 0.0326 - val_accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0337 - accuracy: 0.5286 - val_loss: 0.0322 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0333 - accuracy: 0.5286 - val_loss: 0.0317 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.0329 - accuracy: 0.5286 - val_loss: 0.0313 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0325 - accuracy: 0.5286 - val_loss: 0.0309 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0322 - accuracy: 0.5286 - val_loss: 0.0305 - val_accuracy: 0.6000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0318 - accuracy: 0.5286 - val_loss: 0.0302 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.0315 - accuracy: 0.5286 - val_loss: 0.0298 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.0312 - accuracy: 0.5286 - val_loss: 0.0297 - val_accuracy: 0.6000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0310 - accuracy: 0.5286 - val_loss: 0.0292 - val_accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0309 - accuracy: 0.5286 - val_loss: 0.0296 - val_accuracy: 0.6000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0308 - accuracy: 0.5286 - val_loss: 0.0286 - val_accuracy: 0.6000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.0304 - accuracy: 0.5286 - val_loss: 0.0288 - val_accuracy: 0.6000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.0301 - accuracy: 0.5286 - val_loss: 0.0281 - val_accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0298 - accuracy: 0.5286 - val_loss: 0.0281 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.0296 - accuracy: 0.5286 - val_loss: 0.0276 - val_accuracy: 0.6000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.0293 - accuracy: 0.5286 - val_loss: 0.0276 - val_accuracy: 0.6000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.0291 - accuracy: 0.5286 - val_loss: 0.0272 - val_accuracy: 0.6000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.0289 - accuracy: 0.5286 - val_loss: 0.0274 - val_accuracy: 0.6000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0288 - accuracy: 0.5286 - val_loss: 0.0269 - val_accuracy: 0.6000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.0286 - accuracy: 0.5286 - val_loss: 0.0269 - val_accuracy: 0.6000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0283 - accuracy: 0.5286 - val_loss: 0.0263 - val_accuracy: 0.6000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0281 - accuracy: 0.5286 - val_loss: 0.0264 - val_accuracy: 0.6000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0279 - accuracy: 0.5286 - val_loss: 0.0259 - val_accuracy: 0.6000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0276 - accuracy: 0.5286 - val_loss: 0.0261 - val_accuracy: 0.6000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.0275 - accuracy: 0.5286 - val_loss: 0.0257 - val_accuracy: 0.6000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0274 - accuracy: 0.5286 - val_loss: 0.0259 - val_accuracy: 0.6000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.0273 - accuracy: 0.5286 - val_loss: 0.0255 - val_accuracy: 0.6000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0272 - accuracy: 0.5286 - val_loss: 0.0256 - val_accuracy: 0.6000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.0271 - accuracy: 0.5286 - val_loss: 0.0254 - val_accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0269 - accuracy: 0.5286 - val_loss: 0.0252 - val_accuracy: 0.6000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.0268 - accuracy: 0.5286 - val_loss: 0.0251 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 0.0266 - accuracy: 0.5286 - val_loss: 0.0249 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0264 - accuracy: 0.5286 - val_loss: 0.0247 - val_accuracy: 0.6000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 0.0263 - accuracy: 0.5286 - val_loss: 0.0248 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 408ms/step - loss: 0.0262 - accuracy: 0.5286 - val_loss: 0.0244 - val_accuracy: 0.6000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0261 - accuracy: 0.5286 - val_loss: 0.0249 - val_accuracy: 0.6000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0261 - accuracy: 0.5286 - val_loss: 0.0241 - val_accuracy: 0.6000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0260 - accuracy: 0.5286 - val_loss: 0.0249 - val_accuracy: 0.5889\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0259 - accuracy: 0.5286 - val_loss: 0.0239 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf924a6580>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr_new,\n",
    "          y_tr_new,\n",
    "          epochs=50,\n",
    "          validation_data=(X_test_new, y_tes_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sugerencias\n",
    "- Grabar varias veces las mismas palabras.\n",
    "- Preguntar a Juan Miguel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
