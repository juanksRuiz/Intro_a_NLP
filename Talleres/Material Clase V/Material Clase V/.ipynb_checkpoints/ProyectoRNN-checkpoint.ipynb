{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I: Implementacion de un sistema de Reconocimiento Automático de Habla.\n",
    "\n",
    "El objetivo de este proyecto es utilizar las herramientas vistas en clase para la implementación de un sistema de reconocimiento automático de habla (ASR-Automatic Speech Recognition). Para lograr este objetivo se realizarán dos implementaciones. La primera de ellas utilizará HMM, y est definida en el **Taller II: Implementing a simple ASR system using HMM**. La segunda Implementación se realizará utilizando redes Neuronales Reurrentes (RNN).\n",
    "\n",
    "Par al aimplementación del sistema utilizando RNNs, se utilizara la libreria [TensorFlow](https://pypi.org/project/tensorflow/) de Python, especificamente las funciones para la creación de redes neuronales en [keras](https://www.tensorflow.org/guide/keras/sequential_model) y en particular las relacionadas con las redes neuronales recurrentes [(RNN)](https://www.tensorflow.org/guide/keras/rnn). Pueden utilizar las RNN simples, LTSM o las GRU. Sin emabrgo, las que se estudiaron en clase hasta el momento son las RNN simples. Por otro lado no es necesario que usen las RNNs bidirecionales, o las funciones optimizadas par aGPUs.\n",
    "\n",
    "Para este taller deben seguir los siguientes pasos:\n",
    "\n",
    "1. Cree una base de datos de entrenamiento, utilizando la segmentación de las palabras en fonemas y los espectrogramas de la señal de voz calculados en el Taller II.\n",
    "2. Divida los datos entre datos de entrenamiento y validación. Esto lo puede realizar por medio del uso de  la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de SciKit-Learn.\n",
    "3. Construya un aarquitectura para el ASR usando redes neuronales.\n",
    "4. Evalue el comportamiento del modelo.\n",
    "5. Ajuste el modelo si lo considera adecuado.\n",
    "6. Pruebe con los datos de entrenamiento si el modelo produce la secuencia de fonemas indicada.\n",
    "7. Con el conjunto de palabras de prueba, generado en el taller II, trate de predecir la palbara escrita utilizando el modelo implementado.\n",
    "8. Discuta sobre el comportamiento del sistema ASR utilziando HMM y RNN. La discusión debe contener al menos la respuest aa las siguientes pregutnas:\n",
    "    * ¿Cúal modelo e smás facil de entender?\n",
    "    * ¿Qué modelo funciona mejor? ¿Cúal es la razón para esto?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en HMM?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en RNN?\n",
    "    * ¿Cómo se podria mejorar el sistema desarrollado? ¿Qué hace falta en este sistema ASR?\n",
    "    * ¿Obtuvó los resultados esperados?\n",
    "    \n",
    "Al enviar el proyecto debe incluir los siguientes items:\n",
    "1. Notebook de Jupyter explicando el desarrollo del proyecto, y con la respuesta a las preguntas realiadas.\n",
    "2. Archivos de soporte utilizadso, funciones, etc..\n",
    "3. Grabaciones de las señales de voz utilizadas para entrenar el sistema.\n",
    "4. Grabaciones de las señales de voz utilizadas para probar el sistema.\n",
    "\n",
    "**Nota I:** Una guía rápida par ala implementación del modelo de red neuronal utilizando TensorFlow y Python lo pueden encontrar en este [link](https://www.youtube.com/watch?v=BSpXCRTOLJA).\n",
    "\n",
    "**Nota II:** Recuerde que este proyecto se realiza en grupos de máximo dos personas. También tenga en cuenta que debido a que el taller II hace parte de la evaluación, deben hacerse con el mismo compañero con el que trabajarón ese taller.\n",
    "\n",
    "**Nota III:** El deadline par ala entrega del proyecto es el **Domingo 28 de Febrero del 2021**.\n",
    "\n",
    "**Mucha Suerte!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import scipy as sc\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 8000 # Numero de muestras por segundo\n",
    "nBits = 16 # Numero de bits por muestra del audio\n",
    "ID = -1\n",
    "seconds = 5 # Duracion de la grabacion\n",
    "Nfft = 512\n",
    "fm = np.arange(0, Nfft / 4) * fs / Nfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahijado.wav',\n",
       " 'balocesto.wav',\n",
       " 'espantapajaro.wav',\n",
       " 'jamon.wav',\n",
       " 'kiosko.wav',\n",
       " 'llorar.wav',\n",
       " 'muchacho.wav',\n",
       " 'murcielago.wav',\n",
       " 'sound1.wav',\n",
       " 'sound10.wav',\n",
       " 'sound2.wav',\n",
       " 'sound3.wav',\n",
       " 'sound4.wav',\n",
       " 'sound5.wav',\n",
       " 'sound6.wav',\n",
       " 'sound7.wav',\n",
       " 'sound8.wav',\n",
       " 'sound9.wav',\n",
       " 'terremoto.wav',\n",
       " 'zapato.wav']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = os.listdir('./utils/sounds/')\n",
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahijado.wav': 7,\n",
       " 'balocesto.wav': 10,\n",
       " 'espantapajaro.wav': 13,\n",
       " 'jamon.wav': 5,\n",
       " 'kiosko.wav': 6,\n",
       " 'llorar.wav': 5,\n",
       " 'muchacho.wav': 6,\n",
       " 'murcielago.wav': 10,\n",
       " 'sound1.wav': 4,\n",
       " 'sound10.wav': 8,\n",
       " 'sound2.wav': 5,\n",
       " 'sound3.wav': 5,\n",
       " 'sound4.wav': 5,\n",
       " 'sound5.wav': 8,\n",
       " 'sound6.wav': 6,\n",
       " 'sound7.wav': 7,\n",
       " 'sound8.wav': 6,\n",
       " 'sound9.wav': 5,\n",
       " 'terremoto.wav': 8,\n",
       " 'zapato.wav': 6}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantidad_fonemas = [7,10,13,5,6,5,6,10,4,8,5,5,5,8,6,7,6,5,8,6]\n",
    "dicc = {}\n",
    "for idx,i in enumerate(nombres):\n",
    "    dicc[i] = cantidad_fonemas[idx]\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAudios(nombres):\n",
    "    audios = []\n",
    "    for i in nombres:\n",
    "        y_aux, fs_aux = sf.read('./utils/sounds/' + i)\n",
    "        if len(y_aux.shape) > 1:\n",
    "            y_aux = y_aux[:,0]\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        else:\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        audios.append(y)\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMelSpectogram(audios,fs,Nfft):\n",
    "    spectograms = []\n",
    "    for i in audios:\n",
    "        Sm = librosa.feature.melspectrogram(y=i, sr=fs, n_fft=Nfft, n_mels = 39)\n",
    "        spectograms.append(Sm)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = getAudios(nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectograms = getMelSpectogram(audios,fs,Nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_codificadas = [[1,9,10,11,1,5,18], [2,1,13,18,16,3,6,22,23,18],[6,22,19,1,16,23,1,19,1,11,1,20,18],\n",
    "                        [11,1,15,18,16],[12,10,18,22,12,18], [14,18,20,1,20],[15,24,4,1,4,18],[15,24,20,3,10,6,13,1,8,18],\n",
    "                        [7,6,4,1], [2,10,14,6,23,6,20,1],[13,10,2,20,18],[13,1,19,10,3],[12,18,21,6,20],[23,6,13,6,7,18,16,18],\n",
    "                        [19,24,6,20,23,1],[19,1,16,23,1,14,1],[11,10,15,6,16,1],[21,6,8,13,1],[23,6,21,6,15,18,23,18],[3,1,19,1,23,18]]\n",
    "for p in palabras_codificadas:\n",
    "    p.insert(0,0)\n",
    "    p.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_countFon = {}\n",
    "for i in range(0,27):\n",
    "    ocurrencia = 0\n",
    "    for j in palabras_codificadas:\n",
    "        ocurrencia += j.count(i)\n",
    "    dicc_countFon[i] = ocurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneCode(palabras_codificadas):\n",
    "    palabras_onecode = []\n",
    "    for palabra in palabras_codificadas:\n",
    "        matriz = np.zeros((24,len(palabra)))\n",
    "        for i in range(len(palabra)):\n",
    "            if palabra[i] > 17 and palabra[i] <= 24:\n",
    "                matriz[palabra[i] - 1,i] = 1\n",
    "            else:\n",
    "                matriz[palabra[i],i] = 1\n",
    "        palabras_onecode.append(matriz)\n",
    "    return palabras_onecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_1_0 = getOneCode(palabras_codificadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta\n",
    "\n",
    "Cual es la interpretacion de realizar el split de esta forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiene que ser agregando columnas de silencio por ende las que son distintas de  24, a las que se agrega 0s a la izquierda y a la derecha\n",
    "mat_1_0 = [] \n",
    "new_col = np.array([1]+23*[0]).reshape([24,1])\n",
    "for i in range(len(matrices_1_0)):\n",
    "    m = deepcopy(matrices_1_0[i])\n",
    "    add_left_flag = True\n",
    "    while m.shape[1] < 39:\n",
    "        if add_left_flag:\n",
    "            m = np.concatenate([new_col,m],axis=1)\n",
    "            add_left_flag = False\n",
    "        else:\n",
    "            m = np.concatenate([m,new_col],axis=1)\n",
    "            add_left_flag = True\n",
    "    mat_1_0.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Spectograms, mat_1_0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando matriz de espectrograma a tensor\n",
    "# Se crea un tensor de (p,q,r) con p: numero de espectrogramas, q: numero de filas, r: numero de columnas\n",
    "# r se fija en el valor maximo de numero de columnas entre todos los espectrogramas para que todos los \n",
    "# espectrogramas tengan la misma dimension en el tensor\n",
    "\n",
    "# Para datos de entrenamiento \n",
    "max_dim_tr = max([X_train[i].shape[1] for i in range(len(X_train))])\n",
    "X_tr_new = np.zeros((len(X_train),39,max_dim_tr))\n",
    "for i in range(len(X_tr_new)):\n",
    "    X_tr_new[i,:,0:X_train[i].shape[1]] = X_train[i]\n",
    "    \n",
    "# Para datos de prueba\n",
    "max_dim_test = max([X_test[i].shape[1] for i in range(len(X_test))])\n",
    "X_test_new = np.zeros((len(X_test),39,max_dim_test))\n",
    "for i in range(len(X_test_new)):\n",
    "    X_test_new[i,:,0:X_test[i].shape[1]] = X_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 39), (24, 39), (24, 39), (24, 39), (24, 39), (24, 39)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_new = \n",
    "[m.shape for m in y_train]\n",
    "#y_test_new = \n",
    "[m.shape for m in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 24)\n",
      "(39, 24)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_new[0].shape)\n",
    "print(y_test_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_nuevo.shape[:2]), activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# Capa de salida: numero de clases de salida: numero de fonemas utilizados\n",
    "n_out = 24 # fonemas que aparecen en palabras incluyebndo el silencio\n",
    "model.add(Dense(n_out, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 14\n  y sizes: 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-c096e64d863e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(X_tr_new,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           validation_data=(X_test, y_test))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 14\n  y sizes: 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(X_tr_new,\n",
    "          y_train,\n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
