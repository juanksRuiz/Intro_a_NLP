{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I: Implementacion de un sistema de Reconocimiento Automático de Habla.\n",
    "\n",
    "El objetivo de este proyecto es utilizar las herramientas vistas en clase para la implementación de un sistema de reconocimiento automático de habla (ASR-Automatic Speech Recognition). Para lograr este objetivo se realizarán dos implementaciones. La primera de ellas utilizará HMM, y est definida en el **Taller II: Implementing a simple ASR system using HMM**. La segunda Implementación se realizará utilizando redes Neuronales Reurrentes (RNN).\n",
    "\n",
    "Par al aimplementación del sistema utilizando RNNs, se utilizara la libreria [TensorFlow](https://pypi.org/project/tensorflow/) de Python, especificamente las funciones para la creación de redes neuronales en [keras](https://www.tensorflow.org/guide/keras/sequential_model) y en particular las relacionadas con las redes neuronales recurrentes [(RNN)](https://www.tensorflow.org/guide/keras/rnn). Pueden utilizar las RNN simples, LTSM o las GRU. Sin emabrgo, las que se estudiaron en clase hasta el momento son las RNN simples. Por otro lado no es necesario que usen las RNNs bidirecionales, o las funciones optimizadas par aGPUs.\n",
    "\n",
    "Para este taller deben seguir los siguientes pasos:\n",
    "\n",
    "1. Cree una base de datos de entrenamiento, utilizando la segmentación de las palabras en fonemas y los espectrogramas de la señal de voz calculados en el Taller II.\n",
    "2. Divida los datos entre datos de entrenamiento y validación. Esto lo puede realizar por medio del uso de  la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de SciKit-Learn.\n",
    "3. Construya un aarquitectura para el ASR usando redes neuronales.\n",
    "4. Evalue el comportamiento del modelo.\n",
    "5. Ajuste el modelo si lo considera adecuado.\n",
    "6. Pruebe con los datos de entrenamiento si el modelo produce la secuencia de fonemas indicada.\n",
    "7. Con el conjunto de palabras de prueba, generado en el taller II, trate de predecir la palbara escrita utilizando el modelo implementado.\n",
    "8. Discuta sobre el comportamiento del sistema ASR utilziando HMM y RNN. La discusión debe contener al menos la respuest aa las siguientes pregutnas:\n",
    "    * ¿Cúal modelo e smás facil de entender?\n",
    "    * ¿Qué modelo funciona mejor? ¿Cúal es la razón para esto?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en HMM?\n",
    "    * ¿Discuta sobre las ventajas y desventajas del modelo basado en RNN?\n",
    "    * ¿Cómo se podria mejorar el sistema desarrollado? ¿Qué hace falta en este sistema ASR?\n",
    "    * ¿Obtuvó los resultados esperados?\n",
    "    \n",
    "Al enviar el proyecto debe incluir los siguientes items:\n",
    "1. Notebook de Jupyter explicando el desarrollo del proyecto, y con la respuesta a las preguntas realiadas.\n",
    "2. Archivos de soporte utilizadso, funciones, etc..\n",
    "3. Grabaciones de las señales de voz utilizadas para entrenar el sistema.\n",
    "4. Grabaciones de las señales de voz utilizadas para probar el sistema.\n",
    "\n",
    "**Nota I:** Una guía rápida par ala implementación del modelo de red neuronal utilizando TensorFlow y Python lo pueden encontrar en este [link](https://www.youtube.com/watch?v=BSpXCRTOLJA).\n",
    "\n",
    "**Nota II:** Recuerde que este proyecto se realiza en grupos de máximo dos personas. También tenga en cuenta que debido a que el taller II hace parte de la evaluación, deben hacerse con el mismo compañero con el que trabajarón ese taller.\n",
    "\n",
    "**Nota III:** El deadline par ala entrega del proyecto es el **Domingo 28 de Febrero del 2021**.\n",
    "\n",
    "**Mucha Suerte!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import scipy as sc\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 8000 # Numero de muestras por segundo\n",
    "nBits = 16 # Numero de bits por muestra del audio\n",
    "ID = -1\n",
    "seconds = 5 # Duracion de la grabacion\n",
    "Nfft = 512\n",
    "fm = np.arange(0, Nfft / 4) * fs / Nfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ahijado.wav',\n",
       " 'balocesto.wav',\n",
       " 'espantapajaro.wav',\n",
       " 'jamon.wav',\n",
       " 'kiosko.wav',\n",
       " 'llorar.wav',\n",
       " 'muchacho.wav',\n",
       " 'murcielago.wav',\n",
       " 'sound1.wav',\n",
       " 'sound10.wav',\n",
       " 'sound2.wav',\n",
       " 'sound3.wav',\n",
       " 'sound4.wav',\n",
       " 'sound5.wav',\n",
       " 'sound6.wav',\n",
       " 'sound7.wav',\n",
       " 'sound8.wav',\n",
       " 'sound9.wav',\n",
       " 'terremoto.wav',\n",
       " 'zapato.wav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = os.listdir('./utils/sounds/')\n",
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahijado.wav': 7,\n",
       " 'balocesto.wav': 10,\n",
       " 'espantapajaro.wav': 13,\n",
       " 'jamon.wav': 5,\n",
       " 'kiosko.wav': 6,\n",
       " 'llorar.wav': 5,\n",
       " 'muchacho.wav': 6,\n",
       " 'murcielago.wav': 10,\n",
       " 'sound1.wav': 4,\n",
       " 'sound10.wav': 8,\n",
       " 'sound2.wav': 5,\n",
       " 'sound3.wav': 5,\n",
       " 'sound4.wav': 5,\n",
       " 'sound5.wav': 8,\n",
       " 'sound6.wav': 6,\n",
       " 'sound7.wav': 7,\n",
       " 'sound8.wav': 6,\n",
       " 'sound9.wav': 5,\n",
       " 'terremoto.wav': 8,\n",
       " 'zapato.wav': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantidad_fonemas = [7,10,13,5,6,5,6,10,4,8,5,5,5,8,6,7,6,5,8,6]\n",
    "dicc = {}\n",
    "for idx,i in enumerate(nombres):\n",
    "    dicc[i] = cantidad_fonemas[idx]\n",
    "dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAudios(nombres):\n",
    "    audios = []\n",
    "    for i in nombres:\n",
    "        y_aux, fs_aux = sf.read('./utils/sounds/' + i)\n",
    "        if len(y_aux.shape) > 1:\n",
    "            y_aux = y_aux[:,0]\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        else:\n",
    "            y = ((1/np.std(y_aux))*y_aux).reshape(len(y_aux))\n",
    "        audios.append(y)\n",
    "    return audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMelSpectogram(audios,fs,Nfft):\n",
    "    spectograms = []\n",
    "    for i in audios:\n",
    "        Sm = librosa.feature.melspectrogram(y=i, sr=fs, n_fft=Nfft, n_mels = 39)\n",
    "        spectograms.append(Sm)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = getAudios(nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectograms = getMelSpectogram(audios,fs,Nfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_codificadas = [[1,9,10,11,1,5,18], [2,1,13,18,16,3,6,22,23,18],[6,22,19,1,16,23,1,19,1,11,1,20,18],\n",
    "                        [11,1,15,18,16],[12,10,18,22,12,18], [14,18,20,1,20],[15,24,4,1,4,18],[15,24,20,3,10,6,13,1,8,18],\n",
    "                        [7,6,4,1], [2,10,14,6,23,6,20,1],[13,10,2,20,18],[13,1,19,10,3],[12,18,21,6,20],[23,6,13,6,7,18,16,18],\n",
    "                        [19,24,6,20,23,1],[19,1,16,23,1,14,1],[11,10,15,6,16,1],[21,6,8,13,1],[23,6,21,6,15,18,23,18],[3,1,19,1,23,18]]\n",
    "for p in palabras_codificadas:\n",
    "    p.insert(0,0)\n",
    "    p.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneCode(palabras_codificadas):\n",
    "    palabras_onecode = []\n",
    "    for palabra in palabras_codificadas:\n",
    "        matriz = np.zeros((27,len(palabra)))\n",
    "        for i in range(len(palabra)):\n",
    "            matriz[palabra[i],i] = 1\n",
    "        palabras_onecode.append(matriz)\n",
    "    return palabras_onecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palabras_one_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4d127f656e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrices_1_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetOneCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpalabras_codificadas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrices_1_0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-bfb83d1066d4>\u001b[0m in \u001b[0;36mgetOneCode\u001b[1;34m(palabras_codificadas)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mmatriz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpalabra\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpalabras_onecode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatriz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpalabras_one_code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'palabras_one_code' is not defined"
     ]
    }
   ],
   "source": [
    "matrices_1_0 = getOneCode(palabras_codificadas)\n",
    "print(matrices_1_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[int(el in list_b_el) for el in ] for list_b_el in list_b]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
